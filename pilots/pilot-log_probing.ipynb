{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410f605b-0939-438a-8475-a6d42edad204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5693461-583f-43c0-acab-519b55452f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I516663\\AppData\\Local\\Temp\\ipykernel_20864\\2864884412.py:14: DtypeWarning: Columns (22,27,28,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(fn)[[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         case_ID                    activityNameEN  org:resource  \\\n",
      "0       10009138  register submission date request       9264148   \n",
      "1       10009138              OLO messaging active       9264148   \n",
      "2       10009138         send confirmation receipt       9264148   \n",
      "5       10009138     create procedure confirmation       9264148   \n",
      "6       10009138      create subcases completeness       9264148   \n",
      "...          ...                               ...           ...   \n",
      "262621   9998898       read publication date field        560600   \n",
      "262622   9998898     registration date publication        560600   \n",
      "262623   9998898      stop all running subcases 2b        560600   \n",
      "262624   9998898                phase case handled        560600   \n",
      "262625   9998898       read publication date field        560600   \n",
      "\n",
      "              Complete Timestamp          ct:last_phase  \\\n",
      "0      2014-04-10 22:00:00+00:00  Beschikking verzonden   \n",
      "1      2014-04-13 22:00:00+00:00  Beschikking verzonden   \n",
      "2      2014-04-13 22:00:00+00:00  Beschikking verzonden   \n",
      "5      2014-04-13 22:00:00+00:00  Beschikking verzonden   \n",
      "6      2014-04-13 22:00:00+00:00  Beschikking verzonden   \n",
      "...                          ...                    ...   \n",
      "262621 2014-03-11 23:00:00+00:00       Zaak afgehandeld   \n",
      "262622 2014-03-11 23:00:00+00:00       Zaak afgehandeld   \n",
      "262623 2014-03-11 23:00:00+00:00       Zaak afgehandeld   \n",
      "262624 2014-03-11 23:00:00+00:00       Zaak afgehandeld   \n",
      "262625 2014-03-11 23:00:00+00:00       Zaak afgehandeld   \n",
      "\n",
      "                                   case_parts     action_code r:municipality  \\\n",
      "0                                Bouw,Reclame    01_HOOFD_010         muni-1   \n",
      "1                                Bouw,Reclame    01_HOOFD_011         muni-1   \n",
      "2                                Bouw,Reclame    01_HOOFD_020         muni-1   \n",
      "5                                Bouw,Reclame  01_HOOFD_065_0         muni-1   \n",
      "6                                Bouw,Reclame  01_HOOFD_110_0         muni-1   \n",
      "...                                       ...             ...            ...   \n",
      "262621  Bouw,Handelen in strijd met regels RO   01_HOOFD_809c         muni-5   \n",
      "262622  Bouw,Handelen in strijd met regels RO   01_HOOFD_101b         muni-5   \n",
      "262623  Bouw,Handelen in strijd met regels RO    01_HOOFD_811         muni-5   \n",
      "262624  Bouw,Handelen in strijd met regels RO    01_HOOFD_815         muni-5   \n",
      "262625  Bouw,Handelen in strijd met regels RO    01_HOOFD_809         muni-5   \n",
      "\n",
      "       ct:permit_type    at:phase tt:month  tt:day tt:weekday tt:ampm  \n",
      "0                Bouw  01_HOOFD_0      Apr  Day_10        Thu      PM  \n",
      "1                Bouw  01_HOOFD_0      Apr  Day_13        Sun      PM  \n",
      "2                Bouw  01_HOOFD_0      Apr  Day_13        Sun      PM  \n",
      "5                Bouw  01_HOOFD_0      Apr  Day_13        Sun      PM  \n",
      "6                Bouw  01_HOOFD_1      Apr  Day_13        Sun      PM  \n",
      "...               ...         ...      ...     ...        ...     ...  \n",
      "262621           Bouw  01_HOOFD_8      Mar  Day_11        Tue      PM  \n",
      "262622           Bouw  01_HOOFD_1      Mar  Day_11        Tue      PM  \n",
      "262623           Bouw  01_HOOFD_8      Mar  Day_11        Tue      PM  \n",
      "262624           Bouw  01_HOOFD_8      Mar  Day_11        Tue      PM  \n",
      "262625           Bouw  01_HOOFD_8      Mar  Day_11        Tue      PM  \n",
      "\n",
      "[193508 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load raw data & Preprocess DataFrame (enrich with derived attributes)\n",
    "log = 'bpic15'\n",
    "\n",
    "preprocess = True\n",
    "\n",
    "if preprocess:\n",
    "    fn = f'../data/raw/{log}.csv'\n",
    "else:\n",
    "    fn = f'../data/processed/{log}.csv'\n",
    "\n",
    "if preprocess:\n",
    "\n",
    "    if log == 'bpic15':\n",
    "        df = pd.read_csv(fn)[[\n",
    "            'case:concept:name', 'activityNameEN', 'org:resource', 'time:timestamp',\n",
    "            'case:last_phase', 'case:parts', 'action_code', 'r:municipality'\n",
    "        ]]\n",
    "        df = df.rename(columns={\n",
    "            # Resource-related\n",
    "            'municipality': 'r:municipality',\n",
    "            'case:concept:name' : 'case_ID',\n",
    "            'time:timestamp': 'Complete Timestamp',\n",
    "            # CT-related\n",
    "            'case:last_phase': 'ct:last_phase', \n",
    "            # AT-related\n",
    "        })\n",
    "        df = df.rename(columns={\n",
    "            'case:parts': 'case_parts'\n",
    "        })\n",
    "        # TODO: derive 'ct:permit_type', 'at:phase'\n",
    "        df = df[~df['case_parts'].isna()]\n",
    "        df['ct:permit_type'] = df.apply(lambda row: 'Bouw' if 'Bouw' in str(row['case_parts']).split(',') else 'Non Bouw', axis=1)\n",
    "\n",
    "        # only look at the main subprocess: \"01_HOOFD\"\n",
    "        df = df[~df['action_code'].isna()]\n",
    "        df = df[df['action_code'].str.startswith('01_HOOFD')]\n",
    "        df['at:phase'] = df['action_code'].apply(lambda code: code[:10])\n",
    "        \n",
    "        # filter meaningless values\n",
    "\n",
    "    # Universal (on Disco outputs)\n",
    "    # derive and append TT related candidate attributes\n",
    "    df['Complete Timestamp'] = pd.to_datetime(df['Complete Timestamp'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    MONTHS = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    df['tt:month'] = df['Complete Timestamp'].apply(lambda ts: MONTHS[ts.month-1])\n",
    "    df['tt:day'] = df['Complete Timestamp'].apply(lambda ts: 'Day_{}'.format(ts.day))\n",
    "    WEEKDAYS = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    df['tt:weekday'] = df['Complete Timestamp'].apply(lambda ts: WEEKDAYS[ts.dayofweek])\n",
    "    df['tt:ampm'] = df['Complete Timestamp'].apply(lambda ts: 'AM' if ts.hour < 12 else 'PM')\n",
    "    \n",
    "    print(df)\n",
    "    df.to_csv(f'../data/processed/{log}.csv')\n",
    "else:\n",
    "    df = pd.read_csv(fn, index_col=0)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df09159-a338-46d9-802b-a19d754924a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 1 1 2 2]\n",
      "Shape: 71 x 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I516663\\AppData\\Local\\Temp\\ipykernel_28720\\169531816.py:16: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_grouped = df.groupby(['org:resource', attr]).size().groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n"
     ]
    }
   ],
   "source": [
    "if log == 'bpic15':\n",
    "#     attr = 'Activity'\n",
    "#     attr = 'r:municipality'\n",
    "#     attr = 'ct:last_phase'\n",
    "#     attr = 'ct:permit_type'\n",
    "#     attr = 'at:phase'\n",
    "#     attr = 'tt:month'\n",
    "#     attr = 'tt:day'\n",
    "#     attr = 'tt:weekday'\n",
    "    attr = 'tt:ampm'\n",
    "\n",
    "l = df.groupby(['org:resource', attr]).size().groupby(level=0).size().to_numpy()\n",
    "print(l)\n",
    "avg_val_per_resource = l.mean()\n",
    "    \n",
    "df_grouped = df.groupby(['org:resource', attr]).size().groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n",
    "df_grouped = df_grouped.reset_index().pivot(index='org:resource', columns=attr, values=0)\n",
    "#print(df_grouped)\n",
    "\n",
    "print(f'Shape: {len(df_grouped)} x {len(df_grouped.columns)}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#f, ax = plt.subplots(figsize=(20, 20))\n",
    "#ax = sns.heatmap(df_grouped.T, square=True, cbar=False, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e648fa-8931-4e62-a9e9-0e250807d76f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyclustertend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# NOTE: the hopkins stat in package `pyclustertend` is defined similarly to https://en.wikipedia.org/wiki/Hopkins_statistic\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Only that the complement is used, i.e., Hopkins = 1 - H, where H is calculated according to the definition shown on Wikipedia\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Hence a value closer to 1 suggests strong clustering tendency\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyclustertend\u001b[39;00m \u001b[39mimport\u001b[39;00m vat, ivat, hopkins\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m scale\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m pdist\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyclustertend'"
     ]
    }
   ],
   "source": [
    "# NOTE: the hopkins stat in package `pyclustertend` is defined similarly to https://en.wikipedia.org/wiki/Hopkins_statistic\n",
    "# Only that the complement is used, i.e., Hopkins = 1 - H, where H is calculated according to the definition shown on Wikipedia\n",
    "# Hence a value closer to 1 suggests strong clustering tendency\n",
    "from pyclustertend import vat, ivat, hopkins\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.spatial.distance import pdist\n",
    "from numpy import mean\n",
    "\n",
    "# scale\n",
    "X = scale(df_grouped.fillna(0).to_numpy())\n",
    "sample_size = int(0.2 * len(X))\n",
    "\n",
    "# binarize (for hacking hamming distance)\n",
    "B = (X > 0)\n",
    "\n",
    "'''\n",
    "# X-related\n",
    "# avg pdist\n",
    "avg_pdist = pdist(X).mean()\n",
    "print(f'Avg. Pairwise distance (Euclidean): \\n{avg_pdist}')\n",
    "# hopkins stat\n",
    "hopkins_stat = mean([hopkins(X, sampling_size=sample_size) for i in range(1000)])\n",
    "print(f'Hopkins statistic averaged over 1k runs, sampling {sample_size} / {len(X)} (20%) points: \\n{hopkins_stat}')\n",
    "'''\n",
    "\n",
    "# B-related\n",
    "# avg pdist\n",
    "avg_pdist_bin = pdist(B, metric='hamming').mean()\n",
    "print(f'Avg. Pairwise distance: \\n{avg_pdist_bin}')\n",
    "# hopkins stat\n",
    "#hopkins_stat_bin = mean([hopkins(B, sampling_size=sample_size) for i in range(1000)])\n",
    "#print(f'Hopkins statistic averaged over 1k runs, sampling {sample_size} / {len(B)} (20%) points: \\n{hopkins_stat_bin}')\n",
    "\n",
    "\n",
    "#print('{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}'.format(avg_val_per_resource, avg_pdist, hopkins_stat, avg_pdist_bin, hopkins_stat_bin))\n",
    "#print('{:.3f},{:.3f},{:.3f}'.format(avg_val_per_resource, avg_pdist_bin, hopkins_stat_bin))\n",
    "print('{:.3f},{:.3f}'.format(avg_val_per_resource, avg_pdist_bin))\n",
    "    \n",
    "#ivat(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87dfdd-39cc-4d86-97ec-a02b8de936ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
